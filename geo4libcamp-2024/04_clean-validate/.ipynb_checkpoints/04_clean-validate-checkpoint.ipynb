{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8921d99a",
   "metadata": {},
   "source": [
    "# Metadata Validation and Clean\n",
    "\n",
    "\n",
    "This script will read a CSV of Aardvark metadata to check for required fields and values:\n",
    "1. Resource Class: Checks for a valid entry; if fails -> \"Other\"\n",
    "2. Access Rights: Checks for a valid entry; if fails -> \"Public\"\n",
    "3. Date Range: Ensures that the second integer is equal or larger than the first\n",
    "4. Format: Checks if Download is present; if so -> \"File\"\n",
    "5. Bounding Box: \n",
    "    - Rounds to 3 decimal points\n",
    "    - Ensures coordinates are in the correct order\n",
    "    - Checks for points or lines and increases north or east by .0001\n",
    "    \n",
    "At the end, the script will write the changes to `cleaning_log.csv` and will create a new CSV with the full metadata and cleaned values. The new metadata file will contain a column to indicate if the row was cleaned or not. The column value will excludes rows where the only cleaning action was coordinate rounding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d6a1f4",
   "metadata": {},
   "source": [
    "This script requires numpy. You can install with this command:\n",
    "\n",
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f20fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53415338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the acceptable values\n",
    "resource_class_values = ['Collections','Datasets','Imagery','Maps','Web services','Websites','Other']\n",
    "access_rights_values = ['Public', 'Restricted']\n",
    "\n",
    "# Load your CSV file into a pandas DataFrame\n",
    "\n",
    "csv_file_path = 'messy-metadata.csv'\n",
    "# csv_file_path = '20240518_scannedRecords.csv'\n",
    "\n",
    "data = pd.read_csv(csv_file_path, low_memory=False)\n",
    "\n",
    "# Create a DataFrame to store cleaning log\n",
    "cleaning_log = pd.DataFrame(columns=['ColumnName', 'OriginalValue', 'CleanedValue', 'CleaningAction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abfbccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'Resource Class'\n",
    "def clean_resource_class(row):\n",
    "    global cleaning_log\n",
    "    resource_class_string = row['Resource Class']\n",
    "    original = resource_class_string\n",
    "\n",
    "    if pd.isnull(resource_class_string):\n",
    "        new_value = 'Datasets'\n",
    "        cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Resource Class', 'OriginalValue': original, 'CleanedValue': new_value, 'CleaningAction': 'Filled empty value with \"Datasets\"'}])], ignore_index=True)\n",
    "        return new_value\n",
    "    else:\n",
    "        resource_classes = resource_class_string.split('|')\n",
    "        new_resource_classes = []\n",
    "\n",
    "        for class_value in resource_classes:\n",
    "            class_value = class_value.strip()\n",
    "            if class_value in resource_class_values:\n",
    "                new_resource_classes.append(class_value)\n",
    "            else:\n",
    "                new_value = 'Other'  # Default value if no match is found\n",
    "                cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Resource Class', 'OriginalValue': class_value, 'CleanedValue': new_value, 'CleaningAction': 'Replaced unrecognized value with \"Other\"'}])], ignore_index=True)\n",
    "                new_resource_classes.append(new_value)\n",
    "\n",
    "        return '|'.join(new_resource_classes)\n",
    "\n",
    "data['Resource Class'] = data.apply(clean_resource_class, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14e323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'Access Rights'\n",
    "access_rights_values = ['Public', 'Restricted']\n",
    "\n",
    "# Ensure 'Access Rights' column exists\n",
    "if 'Access Rights' not in data.columns:\n",
    "    data['Access Rights'] = pd.NA  # Adds the column with missing values\n",
    "\n",
    "\n",
    "def clean_access_rights(row):\n",
    "    global cleaning_log\n",
    "    x = row['Access Rights']\n",
    "    original = x\n",
    "\n",
    "    if pd.isnull(x) or str(x).strip() not in access_rights_values:\n",
    "        x = 'Public'  # Default to 'Public' if the value is missing or not in the list\n",
    "        action = 'Filled empty value with \"Public\"' if pd.isnull(x) else 'Replaced unrecognized value with \"Public\"'\n",
    "        cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Access Rights', 'OriginalValue': original, 'CleanedValue': x, 'CleaningAction': action}])], ignore_index=True)\n",
    "\n",
    "    return x\n",
    "\n",
    "data['Access Rights'] = data.apply(clean_access_rights, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d147d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date_range(row):\n",
    "    global cleaning_log\n",
    "\n",
    "    x = row['Date Range']\n",
    "    original = x\n",
    "    if pd.isnull(x) or x == '':\n",
    "        return x  # returns the original value if it's empty or null\n",
    "    else:\n",
    "        date_ranges = str(x).split('|')\n",
    "        for i in range(len(date_ranges)):\n",
    "            years = date_ranges[i].split('-')\n",
    "\n",
    "            # Check if both years are either digits or 'Unknown'\n",
    "            if all(year.isdigit() for year in years):\n",
    "                if len(years) == 2 and years[0].isdigit() and years[1].isdigit() and int(years[0]) > int(years[1]):\n",
    "                    years = sorted(years, key=lambda y: (y.isdigit(), y))\n",
    "                    date_ranges[i] = '-'.join(years)\n",
    "                    x = '|'.join(date_ranges)\n",
    "                    cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ \n",
    "                        'ID': row['ID'], \n",
    "                        'ColumnName': 'Date Range', \n",
    "                        'OriginalValue': original, \n",
    "                        'CleanedValue': x, \n",
    "                        'CleaningAction': 'Corrected date order'\n",
    "                    }])], ignore_index=True)\n",
    "            else:\n",
    "                # Clear the cell if the condition is not met\n",
    "                x = ''\n",
    "                cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ 'ID': row['ID'], 'ColumnName': 'Date Range', 'OriginalValue': original, 'CleanedValue': x, 'CleaningAction': 'Cleared non-integer date range'}])], ignore_index=True)\n",
    "                break  # Exit the loop as we've cleared the cell\n",
    "\n",
    "        return x\n",
    "\n",
    "data['Date Range'] = data.apply(clean_date_range, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fddd076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Format' column exists\n",
    "if 'Format' not in data.columns:\n",
    "    data['Format'] = pd.NA  # Adds the column with missing values\n",
    "\n",
    "# Updated clean_format function to handle missing 'Format' values\n",
    "def clean_format(row):\n",
    "    global cleaning_log\n",
    "    x = row['Format']\n",
    "    original = x\n",
    "    # Fill 'Format' with 'File' if it is missing, regardless of the 'Download' field status\n",
    "    if pd.isnull(x):\n",
    "        x = 'File'\n",
    "        # Log the action\n",
    "        cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ \n",
    "            'ID': row['ID'], \n",
    "            'ColumnName': 'Format', \n",
    "            'OriginalValue': (original if pd.notnull(original) else 'Missing'),  # Handling for logging\n",
    "            'CleanedValue': x, \n",
    "            'CleaningAction': 'Filled missing Format value with \"File\"'\n",
    "        }])], ignore_index=True)\n",
    "    return x\n",
    "\n",
    "# Apply the clean_format function\n",
    "data['Format'] = data.apply(clean_format, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c325dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Original Bounding Box'] = data.loc[:, 'Bounding Box']\n",
    "# Function to round decimal places\n",
    "def round_coordinates(row):\n",
    "    x = row['Bounding Box']\n",
    "    original = x\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    else:\n",
    "        pairs = x.split(',')\n",
    "        new_pairs = []\n",
    "        for pair in pairs:\n",
    "            coords = pair.split()\n",
    "            new_coords = [str(round(float(coord), 3)) for coord in coords]\n",
    "            new_pair = ' '.join(new_coords)\n",
    "            global cleaning_log\n",
    "            if new_pair != pair:\n",
    "                cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{\n",
    "                    'ID':row['ID'], \n",
    "                    'ColumnName': 'Bounding Box', \n",
    "                    'OriginalValue': pair, \n",
    "                    'CleanedValue': new_pair, \n",
    "                    'CleaningAction': 'Rounded to 3 decimal places'\n",
    "                }])], ignore_index=True)\n",
    "            new_pairs.append(new_pair)\n",
    "        return ','.join(new_pairs)\n",
    "    \n",
    "data['Bounding Box'] = data.apply(round_coordinates, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670c853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the coordinates are in the correct order\n",
    "\n",
    "def correct_bounding_box(row):\n",
    "    global cleaning_log\n",
    "\n",
    "    bounding_box_str = row['Bounding Box']\n",
    "    original = bounding_box_str\n",
    "\n",
    "    try:\n",
    "        west, south, east, north = map(float, bounding_box_str.split(\",\"))\n",
    "        \n",
    "        corrected = False  # Flag to check if correction was made\n",
    "\n",
    "        # Correct latitude: ensure north >= south\n",
    "        if north < south:\n",
    "            north, south = south, north\n",
    "            corrected = True\n",
    "\n",
    "        # Correct longitude: ensure east >= west\n",
    "        if east < west:\n",
    "            east, west = west, east\n",
    "            corrected = True\n",
    "\n",
    "        # Log the correction\n",
    "        if corrected:\n",
    "            new_bounding_box_str = f\"{west},{south},{east},{north}\"\n",
    "            cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{ \n",
    "                'ID': row['ID'], \n",
    "                'ColumnName': 'Bounding Box', \n",
    "                'OriginalValue': original, \n",
    "                'CleanedValue': new_bounding_box_str, \n",
    "                'CleaningAction': 'Corrected bounding box order'\n",
    "            }])], ignore_index=True)\n",
    "            return new_bounding_box_str\n",
    "        else:\n",
    "            return bounding_box_str\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while correcting bounding box: {e}\")\n",
    "        return bounding_box_str  # Return the original if there's an error\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "data['Bounding Box'] = data.apply(correct_bounding_box, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2962ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bounding_box(row):\n",
    "    global cleaning_log\n",
    "\n",
    "    original_coords = str(row['Bounding Box'])\n",
    "    coords = original_coords.split(',')\n",
    "    \n",
    "    if original_coords == '' or original_coords == 'nan' or len(coords) != 4:\n",
    "        return np.nan\n",
    "\n",
    "    west, south, east, north = map(float, coords)\n",
    "\n",
    "    east_modified = False\n",
    "    north_modified = False\n",
    "\n",
    "    if west == east:\n",
    "        east += 0.0001  # Add 0.0001 instead of 0.001\n",
    "        east_modified = True\n",
    "\n",
    "    if south == north:\n",
    "        north += 0.0001  # Add 0.0001 instead of 0.001\n",
    "        north_modified = True\n",
    "\n",
    "    # Format coordinates with four decimal places\n",
    "    new_coords = f\"{west:.3f},{south:.3f},{f'{east:.4f}' if east_modified else f'{east:.3f}'},{f'{north:.4f}' if north_modified else f'{north:.3f}'}\"\n",
    "\n",
    "    original_coords_formatted = f\"{float(coords[0]):.3f},{float(coords[1]):.3f},{float(coords[2]):.3f},{float(coords[3]):.3f}\"\n",
    "    \n",
    "    if new_coords != original_coords_formatted:\n",
    "        cleaning_log = pd.concat([cleaning_log, pd.DataFrame([{\n",
    "            'ID':row['ID'], \n",
    "            'ColumnName': 'Bounding Box', \n",
    "            'OriginalValue': row['Bounding Box'], \n",
    "            'CleanedValue': new_coords, \n",
    "            'CleaningAction': 'Corrected line/point to a box'\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "    return new_coords\n",
    "\n",
    "data['Bounding Box'] = data.apply(clean_bounding_box, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed670c4",
   "metadata": {},
   "source": [
    "## After cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d2bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the cleaning_log to exclude rounding-only actions\n",
    "non_rounding_log = cleaning_log[~cleaning_log['CleaningAction'].str.contains(\"Rounded to\")]\n",
    "\n",
    "# Create a set with all IDs that have non-rounding cleaning actions\n",
    "cleaned_ids = set(non_rounding_log['ID'])\n",
    "\n",
    "cleaned_file_path = \"cleaned_\" + csv_file_path\n",
    "\n",
    "# Create a new column 'Cleaned'\n",
    "data['Cleaned'] = data['ID'].apply(lambda x: 'Yes' if x in cleaned_ids else 'No')\n",
    "\n",
    "# Write the cleaned data to a CSV file\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "cleaning_log.to_csv(\"cleaning_log.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
